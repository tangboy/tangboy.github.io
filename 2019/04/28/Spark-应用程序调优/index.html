<!DOCTYPE html>
<html lang="zh-cn">
  <head><meta name="generator" content="Hexo 3.8.0">
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

<meta name="theme-color" content="#f8f5ec">
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="Spark 应用程序调优(转)">




  <meta name="keywords" content="spark, 分布式计算, 大数据, Anthon">










  <link rel="alternate" href="/default" title="Anthon">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.10.1">



<link rel="canonical" href="http://code-monkey.top/2019/04/28/Spark-应用程序调优/">



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css">




  <link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css">



<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.10.1">



  



  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>









<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null},"toc":true,"fancybox":true,"pjax":true};
</script>

    <title> Spark 应用程序调优(转) - Anthon </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="mobile-header-logo">
    <a href="/." class="logo">Anthon</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            标签
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            关于
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Anthon</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              关于
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Spark 应用程序调优(转)
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-04-28
        </span>
        
        
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#配置参数优化"><span class="toc-text">配置参数优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#资源申请参数"><span class="toc-text">资源申请参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#运行时参数"><span class="toc-text">运行时参数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#接口使用优化"><span class="toc-text">接口使用优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#缓存接口"><span class="toc-text">缓存接口</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#引发Shuffle的相关接口"><span class="toc-text">引发Shuffle的相关接口</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#接口对比"><span class="toc-text">接口对比</span></a></li></ol></li></ol>
    </div>
  </div>



    <div class="post-content">
      
        <p>对于很多刚接触Spark的人来说，可能主要关心数据处理的逻辑，而对于如何高效运行Spark应用程序了解较少。由于Spark是一种分布式内存计算框架，其性能往往受限于CPU、内存、网络等多方面的因素，对于用户来说，如何在有限的资源下高效地运行Spark应用程序显得尤为重要。下面只针对Spark-On-Yarn的一些常用调优策略做详细分析。</p>
<h2 id="配置参数优化"><a href="#配置参数优化" class="headerlink" title="配置参数优化"></a>配置参数优化</h2><h3 id="资源申请参数"><a href="#资源申请参数" class="headerlink" title="资源申请参数"></a>资源申请参数</h3><p>Spark-On-Yarn资源调度由Yarn来管理，用户只需指定Spark应用程序要申请的资源即可。我们首先来理解几个资源配置项，一旦资源配置确定，则只能在这些有限的资源下运行Spark应用程序。</p>
<ul>
<li>num-executors：同时运行的executor数。</li>
<li>executor-cores：一个executor上的core数，表示一次能同时运行的task数。一个Spark应用最多可以同时运行的task数为num-executors*executor-cores。</li>
<li>driver-memory：driver的内存大小。</li>
<li>executor-memory：executor内存大小，视任务处理的数据量大小而定。</li>
</ul>
<p>一开始我们只能通过大致的估算来确定上述资源的配置，例如一个Spark应用程序处理的数据大小为1T，如果读出来默认是500个partitions（可以通过测试运行，从web中查看的到），那么平均每个partition的大小为1T/500≈2G，默认情况下，考虑中间处理过程中的数据膨胀以及一些额外内存消耗，executor中可用于存放rdd的阈值设定为spar.storage.memoryFraction=0.6，所以存储partition需要的内存为executor-memory*0.6，稳妥一点设置executor-memory大于2G/0.6，如果一个executor不止是处理一个partition，假如num-executors设置为100，那么平均每个executor处理的partition为500/100=5，这时如果需要缓存rdd，那么executor-memory就要设置为大于5*2G/0.6；如果读出来的分区数很少（如100），一个partition很大（1T/100≈10G），使得executor-memory有可能OOM，那么就需要考虑加大分区数（调用repartition(numPartitions)等），增加task数量来减少一个task的数据量。一般来说一个executor处理的partition数最好不要超过5个，否则增加num-executors数，接上面的例子，500个分区，配置num-executors为100，每个executor需要处理5个partition。driver-memory的大小取决于最后的action操作，如果是调用collect，那么driver-memory的大小就取决于结果集rdd的大小，如果是调用count，那么driver-memory的大小只需要满足运行需求就够了，对于需要长时间迭代的Spark应用，driver端需要维护rdd的依赖关系，所以需要设置较大的内存。</p>
<a id="more"></a>
<p>上述仅仅是大致估算的资源配置，实际还要根据运行情况不断的调优，以达到资源最大化利用。例如，我们在运行日志中找到如下信息，它表明rdd_0的partition1内存大小为717.5KB，当我们得到这个信息后，就可以再次调整上述参数。</p>
<blockquote>
<p>INFO BlockManagerMasterActor: Added rdd_0_1 in memory on mbk.local:50311 (size: 717.5 KB, free: 332.3 MB)</p>
</blockquote>
<h3 id="运行时参数"><a href="#运行时参数" class="headerlink" title="运行时参数"></a>运行时参数</h3><ol>
<li>spark.serializer</li>
</ol>
<p>序列化对于Spark应用的性能来说，影响是非常大的，它涉及到网络传输以及存储，Spark默认是使用org.apache.spark.serializer.JavaSerializer，内部使用的是Java的ObjectOutputStream框架，这种序列化方式压缩比小，而且速度慢，强烈建议采用kyro序列化方式，它速度快，而且压缩比高，性能是Java序列化的10倍，修改配置spark.serializer=org.apache.spark.serializer.KryoSerializer即可，一般来说使用kyro序列化方式，需要在程序里面对用户自定义的可序列化的类进行注册，例如下面代码所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">conf.registerKryoClasses(<span class="type">Array</span>(classOf[<span class="type">MyClass1</span>], classOf[<span class="type">MyClass2</span>]))</span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br></pre></td></tr></table></figure>
<p>但是如果你不注册，kyro也是可以工作的，只是序列化效率差一点。</p>
<ol>
<li>spark.rdd.compress</li>
</ol>
<p>这个参数决定了RDD Cache的过程中，RDD数据是否需要进一步压缩再Cache到内存或磁盘中，从内存看来，当内存比较稀缺时，如果不做压缩就Cache，就很可能会引发GC拖慢程序，从磁盘看来，压缩后数据量变小以减少磁盘IO。所以如果出现内存吃紧或者磁盘IO问题，就需要考虑启用RDD压缩。默认是关闭的。</p>
<ol>
<li>spark.storage.memoryFraction</li>
</ol>
<p>前面提到的executor-memory决定了每个executor可用内存的大小，而spark.storage.memoryFraction则决定了在这部分内存中有多少可以用于管理RDD Cache数据，剩下的内存用来保证任务运行时各种其它内存空间的需要。spark.executor.memoryFraction默认值为0.6，官方文档建议这个比值不要超过JVM Old Gen区域的比值，因为RDD Cache数据通常都是长期驻留内存的，理论上也就是说最终会被转移到Old Gen区域，如果这部分数据允许的尺寸太大，势必把Old Gen区域占满，造成频繁的FULL GC。如果发现Spark应用在运行过程中发生频繁的FULL GC，就需要考虑减小该配置，所以建议这个配置不要加大，如果内存吃紧，可以考虑采用内存和磁盘的混合缓存模式，进一步减少RDD Cache还可以考虑序列化以及压缩等。</p>
<ol>
<li>spark.shuffle.memoryFraction</li>
</ol>
<p>在启用Spill的情况（spark.shuffle.spill默认开启）下，spark.shuffle.memoryFraction表示Shuffle过程中使用的内存达到总内存多少比例的时候开始Spill。spark.shuffle.memoryFraction默认值为0.2，调整该值可以调整Shuffle过程中Spill的频率。总的来说，如果Spill太过频繁，可以适当增加spark.shuffle.memoryFraction的大小，增加用于Shuffle的内存，减少Spill的次数。然而这样一来为了避免内存溢出，对应的可能需要减少RDD cache占用的内存，即减小spark.storage.memoryFraction的值，这样RDD cache的容量减少，有可能带来性能影响，因此需要综合考虑，如果在你的Spark应用程序中RDD Cache较少，Shuffle数据量较大，就需要把spark.shuffle.memoryFraction调大一些，把spark.storage.memoryFraction调小一些。</p>
<ol>
<li>spark.shuffle.file.buffer.kb</li>
</ol>
<p>每次shuffle过程驻留在内存的buffer大小，在shuffle中间数据的产生过程中可减少硬盘的IO操作。spark.shuffle.file.buffer.kb默认为32，若Spark应用程序运行过程中Shuffle称为瓶颈，根据需要适当的加大该配置。</p>
<h2 id="接口使用优化"><a href="#接口使用优化" class="headerlink" title="接口使用优化"></a>接口使用优化</h2><p>对于Spark新手来说，可能不太了解RDD接口内部实现细节，主要关心业务数据处理，然而这往往导致编写出来的Spark应用程序运行效率不高，资源利用浪费等。下面简单介绍一些常见的Spark应用开发注意细节。</p>
<h3 id="缓存接口"><a href="#缓存接口" class="headerlink" title="缓存接口"></a>缓存接口</h3><p>Spark比MapReduce快的很大一部分原因是它可以把中间结果RDDCache起来，不用每次需要时重新计算。但是如果Cache使用不当，会造成内存吃紧，要么带来不必要的磁盘IO，要么引起频繁的FULL GC，拖慢程序运行。</p>
<p>对于一个需要多次使用的临时RDD（类似于临时变量），尽可能要把它Cache起来，这样这个临时RDD只会计算一次，以后每次都会从Cache里直接取。如下面的例子，需要统计第一个字段大于100的数目和第二个字段大于100的数目，如果data不做Cache，因为只有遇到RDD的Action接口时才出发计算，所以在计算firstCnt时会读一遍数据，计算secondCnt时还会再读一遍数据，这样就造成一些不必要的计算，对data做了Cache后，在计算firstCnt时读一次，计算secondCnt就会直接从Cache中取而不用再次读一次。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.textFile(path)</span><br><span class="line">data.cache()</span><br><span class="line"><span class="keyword">val</span> firstCnt = data.filter(x(<span class="number">0</span>).toInt =&gt; <span class="number">100</span>).count()</span><br><span class="line"><span class="keyword">val</span> secondCnt = data.filter(x(<span class="number">1</span>).toInt =&gt; <span class="number">100</span>).count()</span><br></pre></td></tr></table></figure>
<p>很多时候会看到这样的代码，在对两个RDD进行Join时，把两个RDD都Cache起来再做Join，这里一定要明白一点，没有调用Action接口，计算是不会触发的，下面的代码如果后续不再用到rdd1和rdd2，是没有必要对rdd1和rdd2做Cache的，这里要做Cache的是data。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = <span class="keyword">val</span> data = sc.textFile(path)</span><br><span class="line"><span class="keyword">val</span> rdd1 = data.map(…).cache()</span><br><span class="line"><span class="keyword">val</span> rdd2 = data.map(…).cache()</span><br><span class="line"><span class="keyword">val</span> rdd3 = rdd1.join(rdd2).count()</span><br></pre></td></tr></table></figure>
<p>对于内部需要多次迭代的Spark应用来说，应该尽量将每次迭代用到的临时RDD缓存起来，在这个临时RDD被更新时，需要将旧的缓存手动清除掉。如下例子显示，每次迭代都需要在curRDD基础上进行更新得到updatedRDD，在一轮迭代结束后要更新curRDD为updatedRDD，在更新前手动将之前的curRDDCache清理掉，防止内存被耗光，引发频繁FULL GC。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.textFile(path)</span><br><span class="line"><span class="comment">// some transformations in init(data)</span></span><br><span class="line">varcurRDD = init(data).cache()</span><br><span class="line"><span class="keyword">val</span> result = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">Double</span>]()</span><br><span class="line"><span class="comment">// some transformations and an action in getResult(curRDD)</span></span><br><span class="line">result += getResult(curRDD)</span><br><span class="line"><span class="comment">// Start Iteration</span></span><br><span class="line"><span class="keyword">var</span> changed = <span class="literal">true</span></span><br><span class="line"><span class="keyword">while</span>(changed) &#123;</span><br><span class="line">  <span class="comment">// some transformations in iteration(curRDD)</span></span><br><span class="line">  valupdatedRDD = iteration(curRDD).cache()</span><br><span class="line">  <span class="comment">// getResultand check if the value is changed</span></span><br><span class="line">  <span class="keyword">val</span> x = getResult(updatedRDD)</span><br><span class="line">  <span class="comment">// convergence</span></span><br><span class="line">  <span class="keyword">if</span>(x == result.last) changed = <span class="literal">false</span></span><br><span class="line">  <span class="comment">// Unpersist old RDD and assign new RDD</span></span><br><span class="line">  curRDD.unpersist(<span class="literal">false</span>)</span><br><span class="line">  curRDD = updatedRDD</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在对RDD做缓存时，还应考虑内存大小情况选择合适的缓存方式，Spark提供以下几种缓存：</p>
<ul>
<li>MEMORY_ONLY：直接将RDD对象保存到内存中，Spark默认选项</li>
<li>MEMORY_AND_DISK：当内存不够的时候，保存到磁盘中（内存较为稀缺的时候用，比MEMORY_ONLY占用更少的内存，但是会带来磁盘IO）</li>
<li>MEMORY_ONLY_SER：将RDD序列化后保存到内存中（内存较为稀缺的时候用，比MEMORY_ONLY占用更少的内存）</li>
<li>MEMORY_AND_DISK_SER：将RDD序列化后保存到内存中，内存不够时保存到磁盘中（内存较为稀缺的时候用，比MEMORY_ONLY_SER更安全）</li>
<li>DISK_ONLY：保存到磁盘中（不建议用）</li>
<li>MEMORY_ONLY_2：与MEMORY_ONLY类似，只是保存两份</li>
<li>MEMORY_AND_DISK_2：与MEMORY_AND_DISK类似，只是保存两份</li>
<li>OFF_HEAP ：将序列化后的RDD保存到Tachyon（一种分布式内存文件系统）中，相比于MEMORY_ONLY_SER可以避免GC的额外开销。这种缓存方式还在试验阶段</li>
</ul>
<p>根据具体情况判断使用何种缓存方式，调用的时候直接通过如rdd.persist(StorageLevel.MEMORY_AND_DISK_SER)方式实现，调用rdd.cache()默认是rdd.persist(StorageLevel.MEMORY_ONLY)。</p>
<h3 id="引发Shuffle的相关接口"><a href="#引发Shuffle的相关接口" class="headerlink" title="引发Shuffle的相关接口"></a>引发Shuffle的相关接口</h3><p>一个Spark应用程序运行快慢，往往受限于中间的Shuffle过程，Shuffle涉及到网络以及磁盘IO，是整个Spark应用程序运行过程中较为耗时的阶段。在编写Spark应用程序时，应当尽量减少Shuffle次数。下面列举常见的可能引发Shuffle的接口。</p>
<ul>
<li>distinct</li>
<li>intersection/subtracted</li>
<li>reduceByKey/aggregateByKey</li>
<li>repartition</li>
<li>cogroup</li>
<li>join</li>
<li>sortBy/sortByKey</li>
<li>groupBy/groupByKey</li>
<li>partitionBy</li>
</ul>
<p>如果executor内存不足以处理一个partition，那么这时考虑调用repartition来加大分区数，使得每个partition的数据量减少以至于executor可以处理，一般来说上述接口也可以接受numPartitions参数来指定分区数。上述接口连续调用不一定会带来多次Shuffle，只要partition类型和partition数不变，是不会增加Shuffle次数的，如下代码则只有一次Shuffle：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd.map(x =&gt; (x, x+<span class="number">1</span>)).repartition(<span class="number">1000</span>).reduceByKey(_ + _).count()</span><br></pre></td></tr></table></figure>
<p>然而如下代码却会有两次Shuffle：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd.map(x =&gt; (x, x+<span class="number">1</span>)).repartition(<span class="number">1000</span>).reduceByKey(_ + _, <span class="number">3000</span>).count()</span><br></pre></td></tr></table></figure>
<p>很多人在一开始调用了触发Shuffle的相关接口，后面可能数据膨胀了，发现需要更多的partition，所以在后面调用触发Shuffle的相关接口时加大partition数，这样就会导致多次Shuffle，所以一开始就确定好最后的partition数，以免做不必要的Shuffle。</p>
<h3 id="接口对比"><a href="#接口对比" class="headerlink" title="接口对比"></a>接口对比</h3><ol>
<li>sortBy/sortByKey与takeOrdered</li>
</ol>
<p>有时候我们可能希望对数据集排序取前n条记录，很多人会像如下代码一样实现：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rdd.sortBy(x =&gt; x.key).take(n)</span><br><span class="line"><span class="comment">//or rdd.sortByKey().take(n)</span></span><br></pre></td></tr></table></figure>
<p>然而，有一个更有效的办法，就是按照以下方式实现：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd.takeOrdered(n)</span><br></pre></td></tr></table></figure>
<p>以上两者的区别在于，第一种方式需要把所有partition的排序结果进行归并再取前n条记录，第二种方式是从每个排好序的partition中取出前n条记录最后再归并为n条记录，大大降低了网络IO，提升整体性能。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">groupBy/groupByKey与aggregateByKey</span><br></pre></td></tr></table></figure>
<p>在做分组计算时，首先会想到使用groupBy/groupByKey接口，值得一提的是，groupBy/groupByKey接口特别占用内存，它是把具有相同key值的所有value放到一个buffer数组里，如果某个key对应的value非常多，极其容易引发OutOfMemoryError，通过groupBy/groupByKey实现的分组计算功能是可以通过aggregateByKey或者reduceByKey来实现的，aggregateByKey/reduceByKey内部是通过combineByKey实现的，当内存超过一定阈值会spill到磁盘，相对来说较为安全。当通过groupBy/groupByKey接口最后返回的RDD[(K, V)]中V不是序列时，可以用reduceByKey实现，当V是序列时可以用aggregateByKey实现，例如需要统计key对应的value最大值：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//rdd: RDD[(int, int)]</span></span><br><span class="line">rdd.groupByKey().map((k, vb) =&gt; (k, vb.max))</span><br></pre></td></tr></table></figure>
<p>我们完全可以用reduceByKey来实现上述功能：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd.reduceByKey ((v1, v2) =&gt; <span class="type">Math</span>.max(v1, v2))</span><br></pre></td></tr></table></figure>
<p>再比如，就想返回key对应的所有value：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//rdd: RDD[(int, int)]</span></span><br><span class="line">rdd.groupByKey()</span><br></pre></td></tr></table></figure>
<p>我们完全可以用aggregateByKey来实现上述功能：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rdd. aggregateByKey(<span class="type">Seq</span> ())(</span><br><span class="line">(u, v) =&gt; v::u,</span><br><span class="line">(u1, u2) =&gt; u1 ++ u2</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

      
    </div>

    
      
      

  <div class="post-copyright">
    <p class="copyright-item">
      <span>原文作者: </span>
      <a href="http://code-monkey.top">Anthon</a>
    </p>
    <p class="copyright-item">
      <span>原文链接: </span>
      <a href="http://code-monkey.top/2019/04/28/Spark-应用程序调优/">http://code-monkey.top/2019/04/28/Spark-应用程序调优/</a>
    </p>
    <p class="copyright-item">
      <span>许可协议: </span>
      
      <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
    </p>
  </div>



      
      
    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/spark/">spark</a>
            
              <a href="/tags/分布式计算/">分布式计算</a>
            
              <a href="/tags/大数据/">大数据</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2019/05/27/Zeppelin源码分析-目录结构与modules分析/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Zeppelin源码分析---目录结构与modules分析</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    
    
      <a class="next" href="/2019/04/25/Spark-底层网络模块/">
        <span class="next-text nav-default">Spark 底层网络模块(转)</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
  </div>


        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:tanghuaidong@gmail.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/tangboy" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
        
          <a href="https://www.zhihu.com/people/tang-huai-dong/activities" class="iconfont icon-zhihu" title="zhihu"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    

    
      
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>



<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2015 - 
    
    2019

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Anthon</span>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  

  



    
  



  
  





  
    <script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

  
    <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.10.1"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

  </body>
</html>
