<!DOCTYPE html>
<html lang="zh-cn">
  <head><meta name="generator" content="Hexo 3.8.0">
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

<meta name="theme-color" content="#f8f5ec">
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="机器学习，编程，玩">













  <link rel="alternate" href="/default" title="Anthon">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.10.1">



<link rel="canonical" href="http://code-monkey.top/page/2/">



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css">




  <link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css">



<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.10.1">



  



  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>









<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null},"toc":true,"fancybox":true,"pjax":true};
</script>

    <title> Anthon </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="mobile-header-logo">
    <a href="/." class="logo">Anthon</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            标签
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            关于
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Anthon</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              关于
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <section id="posts" class="posts">
    
      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/06/13/MapReduce之Shuffle过程详述/">MapReduce之Shuffle过程详述</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-06-13
        </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        
          
        

        
          <h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>MapReduce作为Hadoop的编程框架，对于大数据开发或者想要接触大数据开发的开发者来说，是必须要掌握的，它是一种经典大数据计算框架，现在有很多开源项目的内部实现都会直接或间接地借鉴了MR过程的实现。我在经过了一些hadoop项目的开发，然后前几天又系统地学习MapReduc内部实现过程，尤其是学习中间的Shuffle过程之后，准备对这一块做一下总结，希望这篇文章能给需要的人带来一些帮助（文中Shuffle的分析还是以Hadoop1.0为例，这个跟2.0的区别并不是很大）。</p>
<h2 id="总述"><a href="#总述" class="headerlink" title="总述"></a>总述</h2><p>对于MapReduce作业，完整的作业运行流程：</p>
<img src="/2019/06/13/MapReduce之Shuffle过程详述/hadoop.png">
<p>完整过程应该是分为7部分，分别是：</p>
<ol>
<li>作业启动：开发者通过控制台启动作业；</li>
<li>作业初始化：这里主要是切分数据、创建作业和提交作业，与第三步紧密相联；</li>
<li>作业/任务调度：对于1.0版的Hadoop来说就是JobTracker来负责任务调度，对于2.0版的Hadoop来说就是Yarn中的Resource Manager负责整个系统的资源管理与分配，Yarn可以参考IBM的一篇博客(Hadoop新MapReduce框架Yarn详解)[<a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/]；" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/]；</a></li>
<li>Map任务；</li>
<li>Shuffle；</li>
<li>Reduce任务；</li>
<li>作业完成：通知开发者任务完成。</li>
</ol>
<p>而这其中最主要的MapReduce过程，主要是第4、5、6步三部分，这也是本篇博客重点讨论的地方，详细作用如下：</p>
<ol>
<li><strong>Map</strong>:数据输入,做初步的处理,输出形式的中间结果；</li>
<li><strong>Shuffle</strong>:按照partition、key对中间结果进行排序合并,输出给reduce线程；</li>
<li><strong>Reduce</strong>:对相同key的输入进行最终的处理,并将结果写入到文件中。</li>
</ol>
<p>这里先给出官网上关于这个过程的经典流程图：</p>
<img src="/2019/06/13/MapReduce之Shuffle过程详述/mapreduce.png">
<p>上图是把MapReduce过程分为两个部分，而实际上从两边的Map和Reduce到中间的那一大块都属于Shuffle过程，也就是说，Shuffle过程有一部分是在Map端，有一部分是在Reduce端，下文也将会分两部分来介绍Shuffle过程。</p>
<p>对于Hadoop集群，当我们在运行作业时，大部分的情况下，map task与reduce task的执行是分布在不同的节点上的，因此，很多情况下，reduce执行时需要跨节点去拉取其他节点上的map task结果，这样造成了集群内部的网络资源消耗很严重，而且在节点的内部，相比于内存，磁盘IO对性能的影响是非常严重的。如果集群中运行的作业有很多，那么task的执行对于集群内部网络的资源消费非常大。因此，我们对于MapRedue作业Shuffle过程的期望是：</p>
<ul>
<li>完整地从map task端拉取数据到Reduce端；</li>
<li>在跨节点拉取数据时，尽可能地减少对带宽的不必要消耗；</li>
<li>减少磁盘IO对task执行的影响。</li>
</ul>
          <div class="read-more">
            <a href="/2019/06/13/MapReduce之Shuffle过程详述/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/06/12/Zeppelin源码分析-interpreter调试/">Zeppelin源码分析-interpreter调试</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-06-12
        </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        

        
          <p>前面提到了interpreter是以单独的process启动的，想要debug interpreter，需要设置启动interpreter进程的jvm以debug方式启动，然后让IDE进行remote debug，具体步骤如下：</p>
<ol>
<li>在bin/interpreter.sh脚本中JAVA_INTP_OPTS变量中加入如下参数：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_INTP_OPTS+=<span class="string">" -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=**`expr <span class="variable">$&#123;PORT&#125;</span> + 1`**  -Dzeppelin.log.file=<span class="variable">$&#123;ZEPPELIN_LOGFILE&#125;</span>"</span></span><br></pre></td></tr></table></figure>
<p>加粗部分保证启动interpreter的jvm以debug方式启动，监听的端口号比RemoteInterpreterServer process监听的端口号+1（采用<code>expr${PORT} + 1</code>）这里不能写成固定的端口，因为每种interpreter都会启动一个独立的process，该process监听的socket端口是zeppelin在运行时随机获取一个可用的端口（没有被占用的端口）。如果写成固定的端口，那么每种interpreter process在进行remote debug的时候，端口就会冲突。</p>
<ol>
<li>启动ZeppelinServer的调试，可以直接run，不用以debug方式启动。</li>
<li>打开浏览器，访问<a href="http://localhost:8080，（如果在shiro.ini中配置了auth，则需要登录），然后创建一个Note，interpreter" target="_blank" rel="noopener">http://localhost:8080，（如果在shiro.ini中配置了auth，则需要登录），然后创建一个Note，interpreter</a> binding了spark。insert一个paragraph，首行写入%spark (表明采用SparkInterpreter来解释此paragrapph中的代码)，换行，写入scala代码println(“hello,world”)，由于这里主要演示debug interpreter，以最简单的hello world说明问题。然后点击运行该paragraph。此时zeppelin server会调用bin/interpreter.sh脚本，传入“端口、interpreter加载的目录(这里是${ZEPPELIN_HOME}/interpreter/spark)、interpreter各自的log file位置”这些参数以启动该interpreter jvm。由于之前在JAVA_INTP_OPTS设置了jvm支持远程调试的参数，该jvm可以通过IDE remote debug。</li>
<li>通过ps –ef|grep interpreter来查找RemoteInterpreterServer process启动的参数，可以看到-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=58679类似的输出，表明该jvm在58679端口上支持remote debug。</li>
</ol>
<p>在SparkInterpreter.java中的重点位置设置断点，如在方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open()和interpret(String line, InterpreterContext context)</span><br></pre></td></tr></table></figure></p>
<p>首行设置断点。</p>
<ol>
<li>在IDE，以Idea为例：创建Remote Run/Debug Configuration，填入端口号58679</li>
</ol>
<img src="/2019/06/12/Zeppelin源码分析-interpreter调试/1.png">
<p>即可启动remote debug。</p>
<p>需要注意的是，由于hello world代码简短，可能在你在IDE中启动Remote debug时该Interpreter已经执行完了。再次点击执行该paragraph即可命中SparkInterpreter中的断点。</p>

        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/06/12/Zeppelin源码分析-note的执行过程/">Zeppelin源码分析-note的执行过程</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-06-12
        </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        
          
        

        
          <img src="/2019/06/12/Zeppelin源码分析-note的执行过程/1.png">
<p>上图是zeppelin的前后台交互模型，zeppelin采用单独的jvm来启动interpreter进程，该Interpreter进程与zeppelinServer进程之间采用Thrift协议通信，其中RemoteInterpreterProcess是Thrift-Client端，而相应的RemoteInterpreterServer是Thrift-Server端。</p>
<p>Paragraph的执行分成“从前端UI提交ParagraphJob到其相关的Interpreter的Scheduler”和“Sheduler执行”2个部分，这2个部分是异步执行的。</p>
<img src="/2019/06/12/Zeppelin源码分析-note的执行过程/2.png">
<p>以上是从前台请求执行指定的Note的指定的Paragraph开始，到该Paragraph提交到Scheduler之间的时序图。这个执行逻辑是与语言无关的。任何语言写的脚本（存储在Paragraph之中）都是上述提交执行的过程。</p>
          <div class="read-more">
            <a href="/2019/06/12/Zeppelin源码分析-note的执行过程/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/06/12/Zeppelin源码分析-notebook持久化/">Zeppelin源码分析-notebook持久化</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-06-12
        </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        
          
        

        
          <p>Notebook的持久化系统主要的类图如下：<br><img src="/2019/06/12/Zeppelin源码分析-notebook持久化/1.png"></p>
<p>各类主要的职责如下：</p>
<ol>
<li>NotebookRepo是顶层接口，规定了持久化层基本的CRUD接口。</li>
<li>NotebookVersioned定义了Note的版本管理接口，目前其实现类只有GitNotebookRepo（该功能目前实现的不完善，既没有实现按照rev log进行过滤检索，界面上目前也没有检索或者是回退到具体某个版本的入口），采用JGit实现。</li>
<li>VFSNotebookRepo是zeppelin的默认实现类，使用apache common-vfs来实现多文件系统支持。（受配置参数zeppelin.notebook.storage控制，参见：ZeppelinConfiguration。</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZEPPELIN_NOTEBOOK_STORAGE("zeppelin.notebook.storage", VFSNotebookRepo.class.getName()),</span><br></pre></td></tr></table></figure>
<p>目前common-vfs支持的文件系统虽然很多，但是由于Notebook持久化时需要RW、Create/Delete权限，实际上可用的只有如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">File System</th>
<th style="text-align:center">Directory Contents</th>
<th style="text-align:center">Authentication</th>
<th style="text-align:center">Read</th>
<th style="text-align:center">Write</th>
<th style="text-align:center">Create/Delete</th>
<th style="text-align:center">Random</th>
<th style="text-align:center">Version</th>
<th style="text-align:center">Rename</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">File</td>
<td style="text-align:center">No</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Read/Write</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Yes</td>
</tr>
<tr>
<td style="text-align:center">FTP</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Read</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Yes</td>
</tr>
<tr>
<td style="text-align:center">FTPS</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
</tr>
<tr>
<td style="text-align:center">RAM</td>
<td style="text-align:center">No</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Read/Write</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Yes</td>
</tr>
<tr>
<td style="text-align:center">RES</td>
<td style="text-align:center">No</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Read/Write</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Yes</td>
</tr>
<tr>
<td style="text-align:center">SFTP</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Read</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Yes</td>
</tr>
<tr>
<td style="text-align:center">Temp</td>
<td style="text-align:center">No</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Read/Write</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Yes</td>
</tr>
<tr>
<td style="text-align:center">WebDAV</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Read/Write</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
</tr>
</tbody>
</table>
</div>
<p>需要注意的是：不支持HDFS，由于vfs对hdfs://不支持Write、Create/Delete</p>
<ol>
<li><p>NotebookRepoSync的初衷是为了让2个NotebookRepo之间进行自动同步修改，实现：在本地repo保存修改的同时，让zeppelin自动将修改同步到远程的repo上。<br>要启用2个repo之间的同步，需要：<br> a. 在zeppelin-site.xml中修改配置参数zeppelin.notebook.storage，以逗号分隔2个实现类的完整类名<br> b. 注意顺序，一般是将VFSNotebookRepo作为一个，而S3NotebookRepo或者是AzureNotebookRepo等作为第二个。zeppelin目前只支持最大2个Repo（maxRepoNum=2作为编译时常量），不能通过配置修改。</p>
</li>
<li><p>S3NotebookRepo和AzureNotebookRepo，实现向2大云存储系统的持久化Notebook。</p>
</li>
<li>ZeppelinHubRepo是为了向zeppelinhub持久化Notebook而设计的，zeppelinhub是一个类似于Github的分享网站，区别在于Github是分享git仓库的，zeppelinhub是分享notebook的。</li>
</ol>
          <div class="read-more">
            <a href="/2019/06/12/Zeppelin源码分析-notebook持久化/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/05/29/Zeppelin源码分析——主要的class分析/">Zeppelin源码分析——主要的class分析</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-05-29
        </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        
          
        

        
          <p>zeppelin的module、package、class众多，如何快速地理清头绪，抓住重点？本文分析zeppelin主要module中重点的类以及它们之间的关系，理清这些类的职责，对于理解zeppelin的运行过程至关重要。<br>经过之前文章的分析，我们已经了解了zeppelin涉及到框架层面的几个module为：zeppelin-server、zeppelin-zengine、zeppelin-interpreter，并且三者之间有如下的依赖关系： </p>
<img src="/2019/05/29/Zeppelin源码分析——主要的class分析/1.png">
<p>本文要分析的主要的class，也都来自于这三个module。</p>
<img src="/2019/05/29/Zeppelin源码分析——主要的class分析/2.png">
<p>以上类图中省略了字段和方法，以避免过早引入太多细节，重点关注类与类之间的关系组成。由于篇幅的限制，再加上zeppelin提供的核心价值是与Interpreter相关的多语言repl解释器，笔者就选择从右上角黄色的区域开始，分多篇分析。</p>
          <div class="read-more">
            <a href="/2019/05/29/Zeppelin源码分析——主要的class分析/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/05/27/Zeppelin源码分析-目录结构与modules分析/">Zeppelin源码分析---目录结构与modules分析</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-05-27
        </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        
          
        

        
          <p><a href="https://zeppelin.apache.org" target="_blank" rel="noopener">Zeppelin</a>，于2016-5-18日从Apache孵化器项目毕业成为Apache顶级项目，采用Java（主要）+Scala+R+PythonR+Bash+JS混合开发，采用maven作为build工具。涉及的主要技术stack如下：</p>
<ol>
<li><strong>前台</strong> : AngularJS、Node.JS、WebSocket、Grunt、Bower、Highlight.js、BootStrap3js</li>
<li><strong>后台</strong> : Jetty（embedding）、Thrift、Shiro（权限）、Apache common-exec、Jersey REST API</li>
</ol>
<p>zeppelin本质上是一个web应用程序，它以独立的jvm进程的方式来启动Interpreter（解释器），交互式（repl）执行各种语言的代码片段，并将结果以html代码片段的形式返回给前端UI。</p>
          <div class="read-more">
            <a href="/2019/05/27/Zeppelin源码分析-目录结构与modules分析/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/04/28/Spark-应用程序调优/">Spark 应用程序调优(转)</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-04-28
        </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        
          
        

        
          <p>对于很多刚接触Spark的人来说，可能主要关心数据处理的逻辑，而对于如何高效运行Spark应用程序了解较少。由于Spark是一种分布式内存计算框架，其性能往往受限于CPU、内存、网络等多方面的因素，对于用户来说，如何在有限的资源下高效地运行Spark应用程序显得尤为重要。下面只针对Spark-On-Yarn的一些常用调优策略做详细分析。</p>
<h2 id="配置参数优化"><a href="#配置参数优化" class="headerlink" title="配置参数优化"></a>配置参数优化</h2><h3 id="资源申请参数"><a href="#资源申请参数" class="headerlink" title="资源申请参数"></a>资源申请参数</h3><p>Spark-On-Yarn资源调度由Yarn来管理，用户只需指定Spark应用程序要申请的资源即可。我们首先来理解几个资源配置项，一旦资源配置确定，则只能在这些有限的资源下运行Spark应用程序。</p>
<ul>
<li>num-executors：同时运行的executor数。</li>
<li>executor-cores：一个executor上的core数，表示一次能同时运行的task数。一个Spark应用最多可以同时运行的task数为num-executors*executor-cores。</li>
<li>driver-memory：driver的内存大小。</li>
<li>executor-memory：executor内存大小，视任务处理的数据量大小而定。</li>
</ul>
<p>一开始我们只能通过大致的估算来确定上述资源的配置，例如一个Spark应用程序处理的数据大小为1T，如果读出来默认是500个partitions（可以通过测试运行，从web中查看的到），那么平均每个partition的大小为1T/500≈2G，默认情况下，考虑中间处理过程中的数据膨胀以及一些额外内存消耗，executor中可用于存放rdd的阈值设定为spar.storage.memoryFraction=0.6，所以存储partition需要的内存为executor-memory*0.6，稳妥一点设置executor-memory大于2G/0.6，如果一个executor不止是处理一个partition，假如num-executors设置为100，那么平均每个executor处理的partition为500/100=5，这时如果需要缓存rdd，那么executor-memory就要设置为大于5*2G/0.6；如果读出来的分区数很少（如100），一个partition很大（1T/100≈10G），使得executor-memory有可能OOM，那么就需要考虑加大分区数（调用repartition(numPartitions)等），增加task数量来减少一个task的数据量。一般来说一个executor处理的partition数最好不要超过5个，否则增加num-executors数，接上面的例子，500个分区，配置num-executors为100，每个executor需要处理5个partition。driver-memory的大小取决于最后的action操作，如果是调用collect，那么driver-memory的大小就取决于结果集rdd的大小，如果是调用count，那么driver-memory的大小只需要满足运行需求就够了，对于需要长时间迭代的Spark应用，driver端需要维护rdd的依赖关系，所以需要设置较大的内存。</p>
          <div class="read-more">
            <a href="/2019/04/28/Spark-应用程序调优/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/04/25/Spark-底层网络模块/">Spark 底层网络模块(转)</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-04-25
        </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        
          
        

        
          <p>对于分布式系统来说，网络是最基本的一环，其设计的好坏直接影响到整个分布式系统的稳定性及可用性。为此，Spark专门独立出基础网络模块spark-network，为上层RPC、Shuffle数据传输、RDD Block同步以及资源文件传输等提供可靠的网络服务。在spark-1.6以前，RPC是单独通过akka实现，数据以及文件传输是通过netty实现，然而akka实质上底层也是采用netty实现，对于一个优雅的工程师来说，不会在系统中同时使用具有重复功能的框架，否则会使得系统越来越重，所以自spark-1.6开始，通过netty封装了一套简洁的类似于akka actor模式的RPC接口，逐步抛弃akka这个大框架。从spark-2.0起，所有的网络功能都是通过netty来实现。</p>
<h2 id="系统抽象"><a href="#系统抽象" class="headerlink" title="系统抽象"></a>系统抽象</h2><p>在介绍spark网络模块前，我们先温习下netty的基本工作流程。无论是服务器还是客户端都会关联一个channel(socket)，channel上会绑定一个pipeline，pipeline绑定若干个handler，用来专门用来处理和业务有关的东西，handler有DownHandler和UpHandler两种，DownHandler用来处理发包，UpHandler用来处理收包，大致过程如下图所示。</p>
<img src="/2019/04/25/Spark-底层网络模块/spark-network-netty-overview.png">
<p>Spark的底层网络实现也是遵循上图所示流程，其总体实现流程如下图所示。客户端发送请求消息，经过Encoder(一种DownHandler)编码，加上包头信息，再通过网络发给服务端，服务端收到消息后，首先经过TransportFrameDecoder(一种UpHandler)处理粘包拆包，得到消息类型和消息体，然后经过Decoder解析消息类型，得到一个个具体的请求消息，最后由TransportChannelHandler处理具体的请求消息，并根据具体的消息类型判断是否返回一个响应。类似地，响应消息传给客户端也是先经过Encoder编码，客户端先通过TransportFrameDecoder、Decoder解包消息，再通过TransportChannelHandler处理具体的响应消息。</p>
<img src="/2019/04/25/Spark-底层网络模块/spark-network-basic.png">
<p>整个网络模型非常清晰简单，最核心的当属消息抽象以及如何定义消息传输和处理，即上图中的Message的定义以及编解码传输等，下面详细介绍spark网络模块的消息抽象以及相关handler的定义。</p>
          <div class="read-more">
            <a href="/2019/04/25/Spark-底层网络模块/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/04/24/Spark-Streaming状态管理应用优化之路/">Spark-Streaming状态管理应用优化之路(转)</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-04-24
        </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        
          
        

        
          <p>通常来说，使用Spark-Streaming做无状态的流式计算是很方便的，每个batch时间间隔内仅需要计算当前时间间隔的数据即可，不需要关注之前的状态。但是很多时候，我们需要对一些数据做跨周期的统计，例如我们需要统计一个小时内每个用户的行为，我们定义的计算间隔(batch-duration)肯定会比一个小时小，一般是数十秒到几分钟左右，每个batch的计算都要更新最近一小时的用户行为，所以需要在整个计算过程中维护一个状态来保存近一个小时的用户行为。在Spark-1.6以前，可以通过updateStateByKey操作实现有状态的流式计算，从spark-1.6开始，新增了mapWithState操作，引入了一种新的流式状态管理机制。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>为了更形象的介绍Spark-Streaming中的状态管理，我们从一个简单的问题展开：我们需要实时统计近一小时内每个用户的行为(点击、购买等)，为了简单，就把这个行为看成点击列表吧，来一条记录，则加到指定用户的点击列表中，并保证点击列表无重复。计算时间间隔为1分钟，即每1分钟更新近一小时用户行为，并将有状态变化的用户行为输出。</p>
          <div class="read-more">
            <a href="/2019/04/24/Spark-Streaming状态管理应用优化之路/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </div>

    

    

  </article>

      
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2019/04/22/Spark-Scheduler内部原理剖析/">Spark Scheduler内部原理剖析(转)</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-04-22
        </span>
        
        
      </div>
    </header>

    
    


    <div class="post-content">
      
        
        
          
        

        
          <p>通过文章<a href="https://code-monkey.top/2019/04/22/Spark%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5RDD/">“Spark核心概念RDD”</a>我们知道，Spark的核心是根据RDD来实现的，Spark Scheduler则为Spark核心实现的重要一环，其作用就是任务调度。Spark的任务调度就是如何组织任务去处理RDD中每个分区的数据，根据RDD的依赖关系构建DAG，基于DAG划分Stage，将每个Stage中的任务发到指定节点运行。基于Spark的任务调度原理，我们可以合理规划资源利用，做到尽可能用最少的资源高效地完成任务计算。</p>
<h2 id="分布式运行框架"><a href="#分布式运行框架" class="headerlink" title="分布式运行框架"></a>分布式运行框架</h2><p>Spark可以部署在多种资源管理平台，例如Yarn、Mesos等，Spark本身也实现了一个简易的资源管理机制，称之为Standalone模式。由于工作中接触较多的是Saprk on Yarn，不做特别说明，以下所述均表示Spark-on-Yarn。Spark部署在Yarn上有两种运行模式，分别为yarn-client和yarn-cluster模式，它们的区别仅仅在于Spark Driver是运行在Client端还是ApplicationMaster端。如下图所示为Spark部署在Yarn上，以yarn-cluster模式运行的分布式计算框架。</p>
<img src="/2019/04/22/Spark-Scheduler内部原理剖析/spark-distribution-framework.png">
<p>其中蓝色部分是Spark里的概念，包括Client、ApplicationMaster、Driver和Executor，其中Client和ApplicationMaster主要是负责与Yarn进行交互；Driver作为Spark应用程序的总控，负责分发任务以及监控任务运行状态；Executor负责执行任务，并上报状态信息给Driver，从逻辑上来看Executor是进程，运行在其中的任务是线程，所以说Spark的任务是线程级别的。通过下面的时序图可以更清晰地理解一个Spark应用程序从提交到运行的完整流程。</p>
<img src="/2019/04/22/Spark-Scheduler内部原理剖析/spark-submit-time.png">
<p>提交一个Spark应用程序，首先通过Client向ResourceManager请求启动一个Application，同时检查是否有足够的资源满足Application的需求，如果资源条件满足，则准备ApplicationMaster的启动上下文，交给ResourceManager，并循环监控Application状态。</p>
<p>当提交的资源队列中有资源时，ResourceManager会在某个NodeManager上启动ApplicationMaster进程，ApplicationMaster会单独启动Driver后台线程，当Driver启动后，ApplicationMaster会通过本地的RPC连接Driver，并开始向ResourceManager申请Container资源运行Executor进程（一个Executor对应与一个Container），当ResourceManager返回Container资源，则在对应的Container上启动Executor。</p>
<p>Driver线程主要是初始化SparkContext对象，准备运行所需的上下文，然后一方面保持与ApplicationMaster的RPC连接，通过ApplicationMaster申请资源，另一方面根据用户业务逻辑开始调度任务，将任务下发到已有的空闲Executor上。</p>
<p>当ResourceManager向ApplicationMaster返回Container资源时，ApplicationMaster就尝试在对应的Container上启动Executor进程，Executor进程起来后，会向Driver注册，注册成功后保持与Driver的心跳，同时等待Driver分发任务，当分发的任务执行完毕后，将任务状态上报给Driver。</p>
<blockquote>
<blockquote>
<p>Driver把资源申请的逻辑给抽象出来，以适配不同的资源管理系统，所以才间接地通过ApplicationMaster去和Yarn打交道。</p>
</blockquote>
</blockquote>
<p>从上述时序图可知，Client只管提交Application并监控Application的状态。对于Spark的任务调度主要是集中在两个方面: 资源申请和任务分发，其主要是通过ApplicationMaster、Driver以及Executor之间来完成，下面详细剖析Spark任务调度每个细节。</p>
          <div class="read-more">
            <a href="/2019/04/22/Spark-Scheduler内部原理剖析/" class="read-more-link">阅读更多</a>
          </div>
        
      
    </div>

    

    

  </article>

      
      
  <nav class="pagination">
    
      <a class="prev" href="/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text">上一页</span>
      </a>
    
    
      <a class="next" href="/page/3/">
        <span class="next-text">下一页</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


    
  </section>

          </div>
          

        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:tanghuaidong@gmail.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/tangboy" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
        
          <a href="https://www.zhihu.com/people/tang-huai-dong/activities" class="iconfont icon-zhihu" title="zhihu"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    

    
      
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>



<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2015 - 
    
    2020

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Anthon</span>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    


    
  



  
  





  
    <script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

  
    <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.10.1"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

  </body>
</html>
