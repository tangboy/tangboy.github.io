<!DOCTYPE html>
<html lang="zh-cn">
  <head><meta name="generator" content="Hexo 3.8.0">
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

<meta name="theme-color" content="#f8f5ec">
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="Spark SQL 性能优化再进一步 CBO 基于代价的优化(转)">




  <meta name="keywords" content="spark, big data, 分布式, sql, CBO, Anthon">










  <link rel="alternate" href="/default" title="Anthon">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.10.1">



<link rel="canonical" href="http://code-monkey.top/2018/12/13/Spark-SQL-性能优化再进一步-CBO-基于代价的优化/">



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css">




  <link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css">



<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.10.1">



  



  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>









<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null},"toc":true,"fancybox":true,"pjax":true};
</script>

    <title> Spark SQL 性能优化再进一步 CBO 基于代价的优化(转) - Anthon </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="mobile-header-logo">
    <a href="/." class="logo">Anthon</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            标签
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            关于
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Anthon</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              关于
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Spark SQL 性能优化再进一步 CBO 基于代价的优化(转)
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-12-13
        </span>
        
        
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark-CBO-背景"><span class="toc-text">Spark CBO 背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark-CBO-原理"><span class="toc-text">Spark CBO 原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Statistics-收集"><span class="toc-text">Statistics 收集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#算子对数据集影响估计"><span class="toc-text">算子对数据集影响估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#算子代价估计"><span class="toc-text">算子代价估计</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Build侧选择"><span class="toc-text">Build侧选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#优化-Join-类型"><span class="toc-text">优化 Join 类型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#优化多表-Join-顺序"><span class="toc-text">优化多表 Join 顺序</span></a></li></ol>
    </div>
  </div>



    <div class="post-content">
      
        <h2 id="Spark-CBO-背景"><a href="#Spark-CBO-背景" class="headerlink" title="Spark CBO 背景"></a>Spark CBO 背景</h2><p>上文<a href="https://code-monkey.top/2018/12/13/Spark-SQL-Catalyst-%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86-%E4%B8%8E-RBO/">Spark SQL 内部原理中介绍的 Optimizer</a> 属于 RBO，实现简单有效。它属于 LogicalPlan 的优化，所有优化均基于 LogicalPlan 本身的特点，未考虑数据本身的特点，也未考虑算子本身的代价。</p>
<p>本文将介绍 CBO，它充分考虑了数据本身的特点（如大小、分布）以及操作算子的特点（中间结果集的分布及大小）及代价，从而更好的选择执行代价最小的物理执行计划，即 SparkPlan。</p>
<h2 id="Spark-CBO-原理"><a href="#Spark-CBO-原理" class="headerlink" title="Spark CBO 原理"></a>Spark CBO 原理</h2><p>CBO 原理是计算所有可能的物理计划的代价，并挑选出代价最小的物理执行计划。其核心在于评估一个给定的物理执行计划的代价。</p>
<p>物理执行计划是一个树状结构，其代价等于每个执行节点的代价总合，如下图所示。</p>
<img src="/2018/12/13/Spark-SQL-性能优化再进一步-CBO-基于代价的优化/spark_sql_cost_model.png">
<p>而每个执行节点的代价，分为两个部分</p>
<ul>
<li>该执行节点对数据集的影响，或者说该节点输出数据集的大小与分布</li>
<li>该执行节点操作算子的代价</li>
</ul>
<p>每个操作算子的代价相对固定，可用规则来描述。而执行节点输出数据集的大小与分布，分为两个部分：1) 初始数据集，也即原始表，其数据集的大小与分布可直接通过统计得到；2)中间节点输出数据集的大小与分布可由其输入数据集的信息与操作本身的特点推算。</p>
<p>所以，最终主要需要解决两个问题</p>
<ul>
<li>如何获取原始数据集的统计信息</li>
<li>如何根据输入数据集估算特定算子的输出数据集</li>
</ul>
<a id="more"></a>
<h3 id="Statistics-收集"><a href="#Statistics-收集" class="headerlink" title="Statistics 收集"></a>Statistics 收集</h3><p>通过如下 SQL 语句，可计算出整个表的记录总数以及总大小</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ANALYZE</span> <span class="keyword">TABLE</span> table_name <span class="keyword">COMPUTE</span> <span class="keyword">STATISTICS</span>;</span><br></pre></td></tr></table></figure>
<p>从如下示例中，Statistics 一行可见， customer 表数据总大小为 37026233 字节，即 35.3MB，总记录数为 28万，与事实相符。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">spark-sql&gt; ANALYZE TABLE customer COMPUTE STATISTICS;</span><br><span class="line">Time taken: 12.888 seconds</span><br><span class="line"></span><br><span class="line">spark-sql&gt; desc extended customer;</span><br><span class="line">c_customer_sk  bigint   NULL</span><br><span class="line">c_customer_id  string   NULL</span><br><span class="line">c_current_cdemo_sk      bigint  NULL</span><br><span class="line">c_current_hdemo_sk      bigint  NULL</span><br><span class="line">c_current_addr_sk       bigint  NULL</span><br><span class="line">c_first_shipto_date_sk  bigint  NULL</span><br><span class="line">c_first_sales_date_sk   bigint  NULL</span><br><span class="line">c_salutation   string   NULL</span><br><span class="line">c_first_name   string   NULL</span><br><span class="line">c_last_name    string   NULL</span><br><span class="line">c_preferred_cust_flag   string  NULL</span><br><span class="line">c_birth_day    int      NULL</span><br><span class="line">c_birth_month  int      NULL</span><br><span class="line">c_birth_year   int      NULL</span><br><span class="line">c_birth_country string  NULL</span><br><span class="line">c_login string NULL</span><br><span class="line">c_email_address string  NULL</span><br><span class="line">c_last_review_date      string  NULL</span><br><span class="line"></span><br><span class="line"><span class="comment"># Detailed Table Information</span></span><br><span class="line">Database       jason_tpc_ds</span><br><span class="line">Table   customer</span><br><span class="line">Owner   jason</span><br><span class="line">Created Time   Sat Sep 15 14:00:40 CST 2018</span><br><span class="line">Last Access    Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">Created By     Spark 2.3.2</span><br><span class="line">Type    EXTERNAL</span><br><span class="line">Provider       hive</span><br><span class="line">Table Properties        [transient_lastDdlTime=1536997324]</span><br><span class="line">Statistics     37026233 bytes, 280000 rows</span><br><span class="line">Location       hdfs://dw/tpc_ds/customer</span><br><span class="line">Serde Library  org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">InputFormat    org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">OutputFormat   org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">Storage Properties      [field.delim=|, serialization.format=|]</span><br><span class="line">Partition Provider      Catalog</span><br><span class="line">Time taken: 1.691 seconds, Fetched 36 row(s)</span><br></pre></td></tr></table></figure>
<p>通过如下 SQL 语句，可计算出指定列的统计信息</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ANALYZE</span> <span class="keyword">TABLE</span> table_name <span class="keyword">COMPUTE</span> <span class="keyword">STATISTICS</span> <span class="keyword">FOR</span> <span class="keyword">COLUMNS</span> [column1] [,column2] [,column3] [,column4] ... [,columnn];</span><br></pre></td></tr></table></figure>
<p>从如下示例可见，customer 表的 c_customer_sk 列最小值为 1， 最大值为 280000，null 值个数为 0，不同值个数为 274368，平均列长度为 8，最大列长度为 8。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">spark-sql&gt; ANALYZE TABLE customer COMPUTE STATISTICS FOR COLUMNS c_customer_sk, c_customer_id, c_current_cdemo_sk;</span><br><span class="line">Time taken: 9.139 seconds</span><br><span class="line">spark-sql&gt; desc extended customer c_customer_sk;</span><br><span class="line">col_name       c_customer_sk</span><br><span class="line">data_type      bigint</span><br><span class="line"><span class="keyword">comment</span> <span class="literal">NULL</span></span><br><span class="line"><span class="keyword">min</span>     <span class="number">1</span></span><br><span class="line"><span class="keyword">max</span>     <span class="number">280000</span></span><br><span class="line">num_nulls      <span class="number">0</span></span><br><span class="line">distinct_count <span class="number">274368</span></span><br><span class="line">avg_col_len    <span class="number">8</span></span><br><span class="line">max_col_len    <span class="number">8</span></span><br><span class="line">histogram      <span class="literal">NULL</span></span><br></pre></td></tr></table></figure>
<p>除上述示例中的统计信息外，Spark CBO 还直接等高直方图。在上例中，histogram 为 NULL。其原因是，spark.sql.statistics.histogram.enabled 默认值为 false，也即 ANALYZE 时默认不计算及存储 histogram。</p>
<p>下例中，通过 <code>SET spark.sql.statistics.histogram.enabled=true;</code> 启用 histogram 后，完整的统计信息如下。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">spark-sql&gt; ANALYZE TABLE customer COMPUTE STATISTICS FOR COLUMNS c_customer_sk,c_customer_id,c_current_cdemo_sk,c_current_hdemo_sk,c_current_addr_sk,c_first_shipto_date_sk,c_first_sales_date_sk,c_salutation,c_first_name,c_last_name,c_preferred_cust_flag,c_birth_day,c_birth_month,c_birth_year,c_birth_country,c_login,c_email_address,c_last_review_date;</span><br><span class="line">Time taken: 125.624 seconds</span><br><span class="line"></span><br><span class="line">spark-sql&gt; desc extended customer c_customer_sk;</span><br><span class="line">col_name       c_customer_sk</span><br><span class="line">data_type      bigint</span><br><span class="line"><span class="keyword">comment</span> <span class="literal">NULL</span></span><br><span class="line"><span class="keyword">min</span>     <span class="number">1</span></span><br><span class="line"><span class="keyword">max</span>     <span class="number">280000</span></span><br><span class="line">num_nulls      <span class="number">0</span></span><br><span class="line">distinct_count <span class="number">274368</span></span><br><span class="line">avg_col_len    <span class="number">8</span></span><br><span class="line">max_col_len    <span class="number">8</span></span><br><span class="line">histogram       height: <span class="number">1102.3622047244094</span>, num_of_bins: <span class="number">254</span></span><br><span class="line">bin_0   lower_bound: <span class="number">1.0</span>, upper_bound: <span class="number">1090.0</span>, distinct_count: <span class="number">1089</span></span><br><span class="line">bin_1   lower_bound: <span class="number">1090.0</span>, upper_bound: <span class="number">2206.0</span>, distinct_count: <span class="number">1161</span></span><br><span class="line">bin_2   lower_bound: <span class="number">2206.0</span>, upper_bound: <span class="number">3286.0</span>, distinct_count: <span class="number">1124</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">bin_251 lower_bound: <span class="number">276665.0</span>, upper_bound: <span class="number">277768.0</span>, distinct_count: <span class="number">1041</span></span><br><span class="line">bin_252 lower_bound: <span class="number">277768.0</span>, upper_bound: <span class="number">278870.0</span>, distinct_count: <span class="number">1098</span></span><br><span class="line">bin_253 lower_bound: <span class="number">278870.0</span>, upper_bound: <span class="number">280000.0</span>, distinct_count: <span class="number">1106</span></span><br></pre></td></tr></table></figure>
<p>从上图可见，生成的 histogram 为 equal-height histogram，且高度为 1102.36，bin 数为 254。其中 bin 个数可由 spark.sql.statistics.histogram.numBins 配置。对于每个 bin，匀记录其最小值，最大值，以及 distinct count。</p>
<p>值得注意的是，这里的 distinct count 并不是精确值，而是通过 HyperLogLog 计算出来的近似值。使用 HyperLogLog 的原因有二</p>
<ul>
<li>使用 HyperLogLog 计算 distinct count 速度快速</li>
<li>HyperLogLog 计算出的 distinct count 可以合并。例如可以直接将两个 bin 的 HyperLogLog 值合并算出</li>
<li>这两个 bin 总共的 distinct count，而无须从重新计算，且合并结果的误差可控</li>
</ul>
<h3 id="算子对数据集影响估计"><a href="#算子对数据集影响估计" class="headerlink" title="算子对数据集影响估计"></a>算子对数据集影响估计</h3><p>对于中间算子，可以根据输入数据集的统计信息以及算子的特性，可以估算出输出数据集的统计结果。</p>
<img src="/2018/12/13/Spark-SQL-性能优化再进一步-CBO-基于代价的优化/spark_cbo_operator_estimation.png">
<p>本节以 Filter 为例说明算子对数据集的影响。</p>
<p>对于常见的 <code>Column A &lt; value B Filter</code>，可通过如下方式估算输出中间结果的统计信息</p>
<ul>
<li>若 B &lt; A.min，则无数据被选中，输出结果为空</li>
<li>若 B &gt; A.max，则全部数据被选中，输出结果与 A 相同，且统计信息不变</li>
<li>若 A.min &lt; B &lt; A.max，则被选中的数据占比为 (B.value - A.min) / (A.max - A.min)，A.min 不变，A.max 更新为 B.value，A.ndv = A.ndv * (B.value - A.min) / (A.max - A.min)</li>
</ul>
<img src="/2018/12/13/Spark-SQL-性能优化再进一步-CBO-基于代价的优化/spark_cbo_filter_estimation.png">
<p>上述估算的前提是，字段 A 数据均匀分布。但很多时候，数据分布并不均匀，且当数据倾斜严重是，上述估算误差较大。此时，可充分利用 histogram 进行更精确的估算</p>
<img src="/2018/12/13/Spark-SQL-性能优化再进一步-CBO-基于代价的优化/spark_cbo_equal_height_histogram.png">
<p>启用 Historgram 后，Filter <code>Column A &lt; value B</code>的估算方法为</p>
<ul>
<li>若 B &lt; A.min，则无数据被选中，输出结果为空</li>
<li>若 B &gt; A.max，则全部数据被选中，输出结果与 A 相同，且统计信息不变</li>
<li>若 A.min &lt; B &lt; A.max，则被选中的数据占比为 height(&lt;B) / height(All)，A.min 不变，A.max = B.value，A.ndv = ndv(&lt;B)</li>
</ul>
<p>在上图中，B.value = 15，A.min = 0，A.max = 32，bin 个数为 10。Filter 后 A.ndv = ndv(&lt;B.value) = ndv(&lt;15)。该值可根据 A &lt; 15 的 5 个 bin 的 ndv 通过 HyperLogLog 合并而得，无须重新计算所有 A &lt; 15 的数据。</p>
<h3 id="算子代价估计"><a href="#算子代价估计" class="headerlink" title="算子代价估计"></a>算子代价估计</h3><p>SQL 中常见的操作有 Selection（由 select 语句表示），Filter（由 where 语句表示）以及笛卡尔乘积（由 join 语句表示）。其中代价最高的是 join。</p>
<p>Spark SQL 的 CBO 通过如下方法估算 join 的代价</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Cost = rows * weight + size * (1 - weight)</span><br><span class="line">Cost = CostCPU * weight + CostIO * (1 - weight)</span><br></pre></td></tr></table></figure>
<p>其中 rows 即记录行数代表了 CPU 代价，size 代表了 IO 代价。weight 由 spark.sql.cbo.joinReorder.card.weight 决定，其默认值为 0.7。</p>
<h2 id="Build侧选择"><a href="#Build侧选择" class="headerlink" title="Build侧选择"></a>Build侧选择</h2><p>对于两表Hash Join，一般选择小表作为build size，构建哈希表，另一边作为 probe side。未开启 CBO 时，根据表原始数据大小选择 t2 作为build side</p>
<img src="/2018/12/13/Spark-SQL-性能优化再进一步-CBO-基于代价的优化/spark_cbo_build_side.png">
<p>而开启 CBO 后，基于估计的代价选择 t1 作为 build side。更适合本例</p>
<img src="/2018/12/13/Spark-SQL-性能优化再进一步-CBO-基于代价的优化/spark_cbo_build_side_selection.png">
<h2 id="优化-Join-类型"><a href="#优化-Join-类型" class="headerlink" title="优化 Join 类型"></a>优化 Join 类型</h2><p>在 Spark SQL 中，Join 可分为 Shuffle based Join 和 BroadcastJoin。Shuffle based Join 需要引入 Shuffle，代价相对较高。BroadcastJoin 无须 Join，但要求至少有一张表足够小，能通过 Spark 的 Broadcast 机制广播到每个 Executor 中。</p>
<p>在不开启 CBO 中，Spark SQL 通过 spark.sql.autoBroadcastJoinThreshold 判断是否启用 BroadcastJoin。其默认值为 10485760 即 10 MB。</p>
<p>并且该判断基于参与 Join 的表的原始大小。</p>
<p>在下图示例中，Table 1 大小为 1 TB，Table 2 大小为 20 GB，因此在对二者进行 join 时，由于二者都远大于自动 BroatcastJoin 的阈值，因此 Spark SQL 在未开启 CBO 时选用 SortMergeJoin 对二者进行 Join。</p>
<p>而开启 CBO 后，由于 Table 1 经过 Filter 1 后结果集大小为 500 GB，Table 2 经过 Filter 2 后结果集大小为 10 MB 低于自动 BroatcastJoin 阈值，因此 Spark SQL 选用 BroadcastJoin。</p>
<img src="/2018/12/13/Spark-SQL-性能优化再进一步-CBO-基于代价的优化/spark_cbo_join_type.png">
<h2 id="优化多表-Join-顺序"><a href="#优化多表-Join-顺序" class="headerlink" title="优化多表 Join 顺序"></a>优化多表 Join 顺序</h2><p>未开启 CBO 时，Spark SQL 按 SQL 中 join 顺序进行 Join。极端情况下，整个 Join 可能是 left-deep tree。在下图所示 TPC-DS Q25 中，多路 Join 存在如下问题，因此耗时 241 秒。</p>
<ul>
<li>left-deep tree，因此所有后续 Join 都依赖于前面的 Join 结果，各 Join 间无法并行进行</li>
<li>前面的两次 Join 输入输出数据量均非常大，属于大 Join，执行时间较长</li>
</ul>
<img src="/2018/12/13/Spark-SQL-性能优化再进一步-CBO-基于代价的优化/spark_cbo_linear_join.png">
<p>开启 CBO 后， Spark SQL 将执行计划优化如下</p>
<img src="/2018/12/13/Spark-SQL-性能优化再进一步-CBO-基于代价的优化/spark_cbo_join_reorder.png">
<p>优化后的 Join 有如下优势，因此执行时间降至 71 秒</p>
<ul>
<li>Join 树不再是 left-deep tree，因此 Join 3 与 Join 4 可并行进行，Join 5 与 Join 6 可并行进行</li>
<li>最大的 Join 5 输出数据只有两百万条结果，Join 6 有 1.49 亿条结果，Join 7相当于小 Join</li>
</ul>

      
    </div>

    
      
      

  <div class="post-copyright">
    <p class="copyright-item">
      <span>原文作者: </span>
      <a href="http://code-monkey.top">Anthon</a>
    </p>
    <p class="copyright-item">
      <span>原文链接: </span>
      <a href="http://code-monkey.top/2018/12/13/Spark-SQL-性能优化再进一步-CBO-基于代价的优化/">http://code-monkey.top/2018/12/13/Spark-SQL-性能优化再进一步-CBO-基于代价的优化/</a>
    </p>
    <p class="copyright-item">
      <span>许可协议: </span>
      
      <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
    </p>
  </div>



      
      
    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/spark/">spark</a>
            
              <a href="/tags/big-data/">big data</a>
            
              <a href="/tags/分布式/">分布式</a>
            
              <a href="/tags/sql/">sql</a>
            
              <a href="/tags/CBO/">CBO</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2018/12/21/Adaptive-Execution-让-Spark-SQL-更高效更智能/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Adaptive Execution 让 Spark SQL 更高效更智能</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    
    
      <a class="next" href="/2018/12/13/Spark-SQL-Catalyst-内部原理-与-RBO/">
        <span class="next-text nav-default">Spark SQL / Catalyst 内部原理 与 RBO(转)</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
  </div>


        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:tanghuaidong@gmail.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/tangboy" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
        
          <a href="https://www.zhihu.com/people/tang-huai-dong/activities" class="iconfont icon-zhihu" title="zhihu"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    

    
      
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>



<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2015 - 
    
    2018

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Anthon</span>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  

  



    
  



  
  





  
    <script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

  
    <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.10.1"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

  </body>
</html>
