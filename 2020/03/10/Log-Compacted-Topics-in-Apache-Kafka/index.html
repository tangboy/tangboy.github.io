<!DOCTYPE html>
<html lang="zh-cn">
  <head><meta name="generator" content="Hexo 3.8.0">
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

<meta name="theme-color" content="#f8f5ec">
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="Log Compacted Topics in Apache Kafka">




  <meta name="keywords" content="Kafka, Log Compacted Topics, Anthon">










  <link rel="alternate" href="/default" title="Anthon">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.10.1">



<link rel="canonical" href="http://code-monkey.top/2020/03/10/Log-Compacted-Topics-in-Apache-Kafka/">



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css">




  <link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css">



<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.10.1">



  



  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>





  <script src="//cdn1.lncld.net/static/js/3.1.1/av-min.js"></script>
  <script id="leancloud">
    AV.init({
      appId: "MMvtgrWtn9BuiNVh6B529AP5-gzGzoHsz",
      appKey: "bA46NPkYiSG0QaBP2vX2ckzl"
    });
  </script>





<script>
  window.config = {"leancloud":{"app_id":"MMvtgrWtn9BuiNVh6B529AP5-gzGzoHsz","app_key":"bA46NPkYiSG0QaBP2vX2ckzl"},"toc":true,"fancybox":true,"pjax":true};
</script>

    <title> Log Compacted Topics in Apache Kafka - Anthon </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="mobile-header-logo">
    <a href="/." class="logo">Anthon</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            标签
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            关于
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Anthon</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              关于
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Log Compacted Topics in Apache Kafka
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-03-10
        </span>
        
        
        <span class="post-visits" data-url="/2020/03/10/Log-Compacted-Topics-in-Apache-Kafka/" data-title="Log Compacted Topics in Apache Kafka">
          阅读次数 0
        </span>
        
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#前提"><span class="toc-text">前提</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Log-Compacted-Topics是什么？"><span class="toc-text">Log Compacted Topics是什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Create-a-Log-Compacted-Topic"><span class="toc-text">Create a Log Compacted Topic</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Segments"><span class="toc-text">Segments</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Cleaning-Process"><span class="toc-text">Cleaning Process</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conclusion"><span class="toc-text">Conclusion</span></a></li></ol>
    </div>
  </div>



    <div class="post-content">
      
        <p>当我开始阅读Kafka官方文档时，尽管看起来Log Compacted Topics是一个简单的概念，但是我并不是很清楚Kafka内部是如何在文件系统中保存他们的状态。通过详细了解这个feature相关的文档，形成这边文档。</p>
<p>在这篇文档中，我会首先描述介绍kafka的log compacted Topics，然后我会介绍Topics是一个简单的概念，但是我并不是很清楚Kafka内部是如何在文件系统中保存他们的状态。</p>
<a id="more"></a>
<h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><p>我假设你已经对应Kafka的基本概念例如，broker、topic、partition、consumer以及producer了解了。而且你本地已经安装了kafka以及zookeeper，且会通过命令行操作kafka</p>
<h2 id="Log-Compacted-Topics是什么？"><a href="#Log-Compacted-Topics是什么？" class="headerlink" title="Log Compacted Topics是什么？"></a>Log Compacted Topics是什么？</h2><p>Kafka官方文档的说法为</p>
<blockquote>
<blockquote>
<p>Log compaction is a mechanism to give finer-grained per-record retention, rather than the coarser-grained time-based retention. The idea is to selectively remove records where we have a more recent update with the same primary key. This way the log is guaranteed to have at least the last state for each key.</p>
</blockquote>
</blockquote>
<p>我们简化上面的说法，其实就是，当在一个partition log中，相同的key有新的记录的时候，Kafka会自动将该key老的记录删除。考虑一下例子，下面一个partition log是一个log compacted topic 名字为latest-product-price:</p>
<img src="/2020/03/10/Log-Compacted-Topics-in-Apache-Kafka/1.jpeg">
<p>如你所见，最开始key p3有两个记录。但是由于这是log compacted topic，因此Kafka会用后台线程(下文会详细介绍)移除老的记录。 现在假设，我们有一个producer并会向这个partition发送新的记录，这个producer分布发送了key为p6、p5、p5三个记录，如下图：</p>
<img src="/2020/03/10/Log-Compacted-Topics-in-Apache-Kafka/2.jpeg">
<p>同样，Kafka Broker内部的后台线程会自动将key为p5和p6的老的记录删除。compacted log是有两部分组成： tail和head. Kafka会保证所有在tail部分的记录的key是唯一的，因为这些数据是在清理线程处理之后的结果，而head部分可能会有多个值。</p>
<p>现在我们需要学习如何通过命令行工具kafka-topics创建一个log compacted topic</p>
<h2 id="Create-a-Log-Compacted-Topic"><a href="#Create-a-Log-Compacted-Topic" class="headerlink" title="Create a Log Compacted Topic"></a>Create a Log Compacted Topic</h2><p>创建一个compacted topic(我会介绍详细配置)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics --create --zookeeper zookeeper:2181 --topic latest-product-price --replication-factor 1 --partitions 1 --config <span class="string">"cleanup.policy=compact"</span> --config <span class="string">"delete.retention.ms=100"</span>  --config <span class="string">"segment.ms=100"</span> --config <span class="string">"min.cleanable.dirty.ratio=0.01"</span></span><br></pre></td></tr></table></figure>
<p>产生一些记录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer --broker-list localhost:9092 --topic latest-product-price --property parse.key=<span class="literal">true</span> --property key.separator=:</span><br><span class="line">&gt;p3:10$</span><br><span class="line">&gt;p5:7$</span><br><span class="line">&gt;p3:11$</span><br><span class="line">&gt;p6:25$</span><br><span class="line">&gt;p6:12$</span><br><span class="line">&gt;p5:14$</span><br><span class="line">&gt;p5:17$</span><br></pre></td></tr></table></figure>
<p>我们注意到，上面的命令key和value的分隔符采用的是:, 现在起一个consumer命令来消费这个topic</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer --bootstrap-server localhost:9092 --topic latest-product-price --property  print.key=<span class="literal">true</span> --property key.separator=: --from-beginning</span><br><span class="line">p3:11$</span><br><span class="line">p6:12$</span><br><span class="line">p5:14$</span><br><span class="line">p5:17$</span><br></pre></td></tr></table></figure>
<p>我们可以看到，一些重复的key已经被删除了。但是p5:14$并没有被删除，这个我在介绍清理进程的时候会介绍。现在我们需要先看一下kafka内部是如何存储消息的。</p>
<h2 id="Segments"><a href="#Segments" class="headerlink" title="Segments"></a>Segments</h2><p>Partition Log事实上是一种抽象概念，目的是方便我们按照顺序消费一个partition中的消息，而不用担心Kafka内部是如何管理和存储的。<br>但是，在实际上，Kafka Broker会将partition log按照需要分割成不同的segments。 Segments都是存储在文件系统中的文件(在data 目录下，并在各个partition下)，并且他们的名字都是以.log结尾。下图是一个partition log被分成三个segments</p>
<img src="/2020/03/10/Log-Compacted-Topics-in-Apache-Kafka/3.jpeg">
<p>如上图可见，一个partition log 存储了7个日志分别处于三个独立的segment file。 一个segment的第一个offset被称为这个segment的base offset。 而segment文件的名称一直都是和base offset相同。</p>
<p>一个partition中的最后一个segment被称为active segment。 只有active segment能够接收新产生的消息。我们将会看到Kafka是如何通过active segment来完成一个compacted log的清理进程的。</p>
<p>回到我们的例子，我们可以通过以下命令产看我们topic partition的segments(假如Kafka的数据存储在<code>/var/lib/kafka/data</code>)：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ls /var/lib/kafka/data/latest-product-price-0/</span><br><span class="line">00000000000000000000.index 00000000000000000006.log</span><br><span class="line">00000000000000000000.log 00000000000000000006.snapshot</span><br><span class="line">00000000000000000000.timeindex 00000000000000000006.timeindex</span><br><span class="line">00000000000000000005.snapshot leader-epoch-checkpoint</span><br><span class="line">00000000000000000006.index</span><br></pre></td></tr></table></figure>
<p>其中<code>00000000000000000000.log</code>和<code>00000000000000000006.log</code>都是这个partition的segment，而<code>00000000000000000006.log</code>是这个partition的active segment</p>
<p>什么时候Kafka会创建一个新的segment？ 一个控制选项是在创建topic的时候通过设置<code>segment.bytes</code>(默认为1GB)来完成。当你的segment size大于这个配置值，Kafka会自动创建一个新的segment。另外一个方式是通过设置<code>segment.ms</code>， 这个选项是通过检查active segment的时间是否老于<code>segment.ms</code>。 如果是，那么kafka会自动创建一个新的segment。在我们上述的命令中，设置<code>segment.ms=100</code>，这样可以保证每100ms会创建一个新的segment。</p>
<p>比较有意思的点在于，当你设置<code>segment.ms=100</code>的时候，你可能想要比较小的segment。当在清理进程结束的时候，Kafka broker会将非活跃的segment合并，并生成一个大的segment。</p>
<p>如果你想更加深入的了解segment以及Kafka相关的内部存储支持，可以参考<a href="https://thehoard.blog/how-kafkas-storage-internals-work-3a29b02e026" target="_blank" rel="noopener">How Kafka’s Storage Internal Work</a> 和<a href="https://medium.com/@durgaswaroop/a-practical-introduction-to-kafka-storage-internals-d5b544f6925f" target="_blank" rel="noopener">A Practical Introduction to Kafka Storage Internals</a></p>
<h2 id="Cleaning-Process"><a href="#Cleaning-Process" class="headerlink" title="Cleaning Process"></a>Cleaning Process</h2><p>在启动的时候，Kafka Broker会创建一定数量的cleaner threads， 负责清理compacted log(而这个线程的数量是通过<code>log.cleaner.threads</code>配置来设置)。这些清理线程，通常都是会找出broker中的最需要清理(filthiest)的日志，并尝试清理掉。对于每个日志，它会计算这个日志的dirty ratio:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dirty ratio = the number of bytes in the head / total number of bytes in the log(tail + head)</span><br></pre></td></tr></table></figure></p>
<p>清理线程会选择dirty ratio最高的日志，这个日志被称为<code>filthiest log</code>。如果这个日志的dirty ratio大于<code>min.cleanable.dirty.ratio</code>， 那么清理线程就会开始清理该日志。否则，清理线程会等待一段时间(通过<code>log.cleaner.backoff.ms</code>配置)。</p>
<p>当找到<code>filthiest log</code>之后，我们想进一步找到这个日志能够被清理的部分。我们注意到，日志有些部分不能被清理且不会被扫描</p>
<ul>
<li>所有active segment中的记录。这也是为什么我们看到p:14$这个重复key记录存在在我们的consumer中</li>
<li>如果你设置了<code>min.compaction.lag.ms</code>并且这个值大于0，那么任何segment中的一个记录的时间如果比距离现在的时间小于该值，那么也不会被清理。这些segments也不会被扫描</li>
</ul>
<p>现在我们知道哪些记录会被compact，就是从日志中的第一个记录到第一个不能够被清理的记录。这篇文章为了简单起见，我们假设在head中的所有记录也是可以被清理的。</p>
<p>我们注意到日中的tail部分只会有唯一key的记录，因为在清理进程的时候，重复的key都已经被删除。因此只有可能在head部分会存在key不唯一的情况。为了能够快速找到这些重复的记录，Kafka为head部分的记录创建了一个map。回到我们的例子，如下</p>
<img src="/2020/03/10/Log-Compacted-Topics-in-Apache-Kafka/4.jpeg">
<p>如上图所示，Kafka创建了一个offset map，用于记录head 部分每个key的值以及对应的最新的offset。如果我们在head部分有重复的key，Kafka只会用最新的offset。如上图，key为p6的记录等等offset为5，而p5的最新offset为7.现在清理线程可以检查日志中的每个记录，删除那些key在offset map中，且offset小于offset map相同key的值的记录。</p>
<p>在清理进程compacted log中，不光重复记录会被删除，kafka会将值为null的记录也一并删除。这些记录被称作<strong>tombstone</strong>。 你可以通过配置<code>delete.retention.ms</code>来延迟删除他们。通过设置该配置，Kafka会检查包含这个记录的segment修改时间，如果修改时间距离当前时间小于该配置值，那么记录会被保留。</p>
<p>现在，记录已经被清理。在清理进程结束之后，我们有了一个新的tail和head。在清理过程中扫码的最后的记录，也就是新tail的最后记录。</p>
<p>Kafka会在数据存储的根目录下的名为<code>cleaner-offset-checkpoint</code>的文件中记录新head的开始offset。这个文件用于下一次清理过程。我们可以查看这个文件如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat /var/lib/kafka/data/cleaner-offset-checkpoint</span><br><span class="line">0</span><br><span class="line">1</span><br><span class="line">latest-product-price 0 6</span><br></pre></td></tr></table></figure>
<p>如上所见，总共有三行。第一行是这个文件的版本(应该是为了前向兼容),第二行值1表示这行之后有多少行，而最后一行宝航了compacted log topic的名字，partition的number，以及这个partition的head offset</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>这篇文章介绍了什么是log compacted topic，以及他们是如何存储和Kafka如何周期性清理的。在文章最后，我先说明，log compaction主要的场景是为了那些只想保留最新记录的cache场景。假设你想在你的应用启动的时候构建一个cache，你可以考虑利用kafka的compacted log topic。</p>

      
    </div>

    
      
      

  <div class="post-copyright">
    <p class="copyright-item">
      <span>原文作者: </span>
      <a href="http://code-monkey.top">Anthon</a>
    </p>
    <p class="copyright-item">
      <span>原文链接: </span>
      <a href="http://code-monkey.top/2020/03/10/Log-Compacted-Topics-in-Apache-Kafka/">http://code-monkey.top/2020/03/10/Log-Compacted-Topics-in-Apache-Kafka/</a>
    </p>
    <p class="copyright-item">
      <span>许可协议: </span>
      
      <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
    </p>
  </div>



      
      
    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/Kafka/">Kafka</a>
            
              <a href="/tags/Log-Compacted-Topics/">Log Compacted Topics</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2020/03/10/Kafka-Connect简介与部署/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Kafka Connect简介与部署</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    
    
      <a class="next" href="/2020/02/25/Flink-Table-SQL-LookableTableSource/">
        <span class="next-text nav-default">Flink Table & SQL LookableTableSource</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
  </div>


        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:tanghuaidong@gmail.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/tangboy" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
        
          <a href="https://www.zhihu.com/people/tang-huai-dong/activities" class="iconfont icon-zhihu" title="zhihu"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    

    
      
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>



<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2015 - 
    
    2020

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Anthon</span>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  

  



    
  



  
  





  
    <script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

  
    <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.10.1"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

  </body>
</html>
